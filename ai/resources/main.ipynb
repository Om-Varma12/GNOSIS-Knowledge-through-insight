{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7695577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "import torch\n",
    "import clip\n",
    "from qdrant_client import QdrantClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01058913",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(\"ViT-B/32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "QDRANT_KEY = os.getenv(\"QDRANT_KEY\")\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "\n",
    "client = QdrantClient(\n",
    "    url = QDRANT_URL,\n",
    "    api_key = QDRANT_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d28eee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='GNOSIS')]\n"
     ]
    }
   ],
   "source": [
    "print(client.get_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d10e2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./WELFake_Dataset.csv/WELFake_Dataset.csv\")\n",
    "# df.head()\n",
    "\n",
    "points = [] # store points to be uploaded in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee20e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef5da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_words=60):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i+max_words]) for i in range(0, len(words), max_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afb54ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "UPLOAD_BATCH = 1000\n",
    "\n",
    "points_buffer = []\n",
    "\n",
    "text_batch = []\n",
    "meta_batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a23aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    title = str(row[\"title\"]) if not pd.isna(row[\"title\"]) else \"\"\n",
    "    text = str(row[\"text\"]) if not pd.isna(row[\"text\"]) else \"\"\n",
    "\n",
    "    full_text = (title + \"\\n\\n\" + text).strip()\n",
    "    if not full_text:\n",
    "        continue\n",
    "\n",
    "    label = int(row[\"label\"])\n",
    "    label_str = \"fake\" if label == 1 else \"real\"\n",
    "\n",
    "    doc_id = f\"datasetX_{row_idx}\"\n",
    "\n",
    "    chunks = chunk_text(full_text, max_words=60)\n",
    "    chunks = chunks[:20]  # üî• LIMIT chunks per doc (VERY IMPORTANT)\n",
    "\n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        text_batch.append(chunk)\n",
    "        meta_batch.append({\n",
    "            \"doc_id\": doc_id,\n",
    "            \"chunk_id\": chunk_idx,\n",
    "            \"title\": title,\n",
    "            \"label\": label_str\n",
    "        })\n",
    "\n",
    "        # When batch is full ‚Üí embed\n",
    "        if len(text_batch) >= BATCH_SIZE:\n",
    "            tokens = clip.tokenize(text_batch, truncate=True).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                vecs = model.encode_text(tokens).cpu().numpy()\n",
    "\n",
    "            # Convert to Qdrant points\n",
    "            for vec, meta, chunk_text_ in zip(vecs, meta_batch, text_batch):\n",
    "                point = {\n",
    "                    \"id\": str(uuid.uuid4()),\n",
    "                    \"vector\": vec.tolist(),\n",
    "                    \"payload\": {\n",
    "                        \"modality\": \"text\",\n",
    "                        \"dataset\": \"WELFake_Dataset\",\n",
    "                        \"chunk_text\": chunk_text_,\n",
    "                        **meta\n",
    "                    }\n",
    "                }\n",
    "                points_buffer.append(point)\n",
    "\n",
    "            # Clear batches\n",
    "            text_batch = []\n",
    "            meta_batch = []\n",
    "\n",
    "            # Upload in chunks\n",
    "            if len(points_buffer) >= UPLOAD_BATCH:\n",
    "                client.upsert(collection_name=\"GNOSIS\", points=points_buffer)\n",
    "                points_buffer = []\n",
    "                \n",
    "            if text_batch:\n",
    "                tokens = clip.tokenize(text_batch, truncate=True).to(device)\n",
    "                with torch.no_grad():\n",
    "                    vecs = model.encode_text(tokens).cpu().numpy()\n",
    "\n",
    "                for vec, meta, chunk_text_ in zip(vecs, meta_batch, text_batch):\n",
    "                    point = {\n",
    "                        \"id\": str(uuid.uuid4()),\n",
    "                        \"vector\": vec.tolist(),\n",
    "                        \"payload\": {\n",
    "                            \"modality\": \"text\",\n",
    "                            \"dataset\": \"your_dataset_name\",\n",
    "                            \"chunk_text\": chunk_text_,\n",
    "                            **meta\n",
    "                        }\n",
    "                    }\n",
    "                    points_buffer.append(point)\n",
    "            \n",
    "            if points_buffer:\n",
    "                client.upsert(collection_name=\"GNOSIS\", points=points_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2914b5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUERY: Clinton says Trump may have violated U.S. law on Cuba\n",
      "================================================================================\n",
      "\n",
      "#1  SCORE = 0.8477\n",
      "--------------------------------------------------------------------------------\n",
      "Text: Clinton says Trump may have violated U.S. law on Cuba CHICAGO (Reuters) - U.S. Democratic presidential nominee Hillary Clinton said on Thursday that Republican opponent Donald Trump may have violated U.S. law, following a news report that one of his companies attempted to do business in Cuba. Newsweek said on Thursday that a hotel and casino company controlled by Trump\n",
      "\n",
      "Meta:\n",
      "  doc_id: datasetX_17640\n",
      "  chunk_id: 0\n",
      "  label: real\n",
      "  title: Clinton says Trump may have violated U.S. law on Cuba\n",
      "\n",
      "#2  SCORE = 0.8110\n",
      "--------------------------------------------------------------------------------\n",
      "Text: whether Trump fills key Latin America posts at the State Department and elsewhere that remain vacant, sources told Reuters. The White House considered making a Cuba announcement on May 20 to mark the 115th anniversary of Cuba‚Äôs independence, but that coincided with Trump‚Äôs overseas trip and the review also was not yet finished, the sources said.\n",
      "\n",
      "Meta:\n",
      "  doc_id: datasetX_11490\n",
      "  chunk_id: 9\n",
      "  label: real\n",
      "  title: Trump administration nearing completion of Cuba policy review: sources\n",
      "\n",
      "#3  SCORE = 0.8103\n",
      "--------------------------------------------------------------------------------\n",
      "Text: he was attempting to do business in Cuba,‚Äù Clinton told reporters on her campaign plane. Clinton and Trump are in a close race ahead of the Nov. 8 presidential election. The Trump campaign did not immediately respond to a Reuters request for comment. Newsweek, citing interviews with former Trump executives, internal company records and court filings, said the Trump company\n",
      "\n",
      "Meta:\n",
      "  doc_id: datasetX_17640\n",
      "  chunk_id: 2\n",
      "  label: real\n",
      "  title: Clinton says Trump may have violated U.S. law on Cuba\n",
      "\n",
      "#4  SCORE = 0.8018\n",
      "--------------------------------------------------------------------------------\n",
      "Text: Trump says he believes Cuba responsible for attacks that hurt U.S. diplomats WASHINGTON (Reuters) - President Donald Trump said on Monday that he believes Havana is responsible for a series of incidents that Washington thinks hurt at least 22 U.S. diplomats over a period of months in Cuba, prompting Washington to scale back its presence there. I do believe Cuba\n",
      "\n",
      "Meta:\n",
      "  doc_id: datasetX_4124\n",
      "  chunk_id: 0\n",
      "  label: real\n",
      "  title: Trump says he believes Cuba responsible for attacks that hurt U.S. diplomats\n",
      "\n",
      "#5  SCORE = 0.7974\n",
      "--------------------------------------------------------------------------------\n",
      "Text: bad things in Cuba, Trump said.\n",
      "\n",
      "Meta:\n",
      "  doc_id: datasetX_21927\n",
      "  chunk_id: 1\n",
      "  label: real\n",
      "  title: Trump says Cuba 'did some bad things' aimed at U.S. diplomats\n"
     ]
    }
   ],
   "source": [
    "client = QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_KEY,\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "# Init CLIP\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "model.eval()\n",
    "\n",
    "# üî• Hardcoded query text\n",
    "QUERY_TEXT = \"Clinton says Trump may have violated U.S. law on Cuba\"\n",
    "\n",
    "# Embed query\n",
    "tokens = clip.tokenize([QUERY_TEXT], truncate=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    vec = model.encode_text(tokens).cpu().numpy()[0]\n",
    "\n",
    "# Search\n",
    "result = client.query_points(\n",
    "    collection_name=\"GNOSIS\",\n",
    "    query=vec.tolist(),\n",
    "    limit=5,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "hits = result.points\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"QUERY:\", QUERY_TEXT)\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, hit in enumerate(hits, 1):\n",
    "    payload = hit.payload\n",
    "    score = hit.score\n",
    "\n",
    "    print(f\"\\n#{i}  SCORE = {score:.4f}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Text:\", payload.get(\"chunk_text\", \"\")[:500])\n",
    "    print(\"\\nMeta:\")\n",
    "    print(\"  doc_id:\", payload.get(\"doc_id\"))\n",
    "    print(\"  chunk_id:\", payload.get(\"chunk_id\"))\n",
    "    print(\"  label:\", payload.get(\"label\"))\n",
    "    print(\"  title:\", payload.get(\"title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13374ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iitGnosisDataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
